{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxEEz3u8yisV"
      },
      "outputs": [],
      "source": [
        "#Importing the pandas library for reading\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_bSlBIyQ3Ozf"
      },
      "outputs": [],
      "source": [
        "path='/content/drive/MyDrive/data/data (2).csv'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7zmJ2HC1ZgP"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ruVM2h73Moqq"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mF1wyPCJ1hTR",
        "outputId": "0a2d776d-0316-486d-894d-aad6eebf2365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgrdzkCr2bNZ"
      },
      "outputs": [],
      "source": [
        "data1 = pd.read_csv(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLSwJ2rh3Vv-",
        "outputId": "e2cc4419-449e-4512-c805-fc97749221f8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method DataFrame.info of              id  target                                       comment_text  \\\n",
              "0        239579  0.4400  This is a great story. Man. I wonder if the pe...   \n",
              "1        239607  0.9125  Yet call out all Muslims for the acts of a few...   \n",
              "2        239644  0.0000  Because the people who drive cars more are the...   \n",
              "3        239653  0.3000  Mormons have had a complicated relationship wi...   \n",
              "4        239744  0.0000                       I'm doing the same thing! :)   \n",
              "...         ...     ...                                                ...   \n",
              "235082  6333915  0.3000  Xi and his comrades must be smirking over Trum...   \n",
              "235083  6333928  0.2000  My thought exactly.  The only people he hasn't...   \n",
              "235084  6333941  0.0000  I agree, Bill G\\nThe vote-buying has begun by ...   \n",
              "235085  6333947  0.0000  No, the probability of dying may be very, very...   \n",
              "235086  6333950  0.2000  Nah, I am too boring to parody.  This guy Camp...   \n",
              "\n",
              "        severe_toxicity  obscene  identity_attack  insult  threat  asian  \\\n",
              "0                     0        0                0       0       0      0   \n",
              "1                     0        0                1       1       0      0   \n",
              "2                     0        0                0       0       0      0   \n",
              "3                     0        0                0       0       0      0   \n",
              "4                     0        0                0       0       0      0   \n",
              "...                 ...      ...              ...     ...     ...    ...   \n",
              "235082                0        0                0       0       0      0   \n",
              "235083                0        0                0       0       0      0   \n",
              "235084                0        0                0       0       0      0   \n",
              "235085                0        0                0       0       0      0   \n",
              "235086                0        0                0       0       0      0   \n",
              "\n",
              "        atheist  ...  month  year  Season  Attack  Disability  Religion  Race  \\\n",
              "0             0  ...      1  2016  Summer       0           0         0     0   \n",
              "1             0  ...      1  2016  Summer       1           0         2     0   \n",
              "2             0  ...      1  2016  Summer       0           0         0     0   \n",
              "3             0  ...      1  2016  Summer       0           0         0     0   \n",
              "4             0  ...      1  2016  Summer       0           0         0     0   \n",
              "...         ...  ...    ...   ...     ...     ...         ...       ...   ...   \n",
              "235082        0  ...     11  2017  Spring       0           0         0     0   \n",
              "235083        0  ...     11  2017  Spring       0           0         0     0   \n",
              "235084        0  ...     11  2017  Spring       0           0         0     0   \n",
              "235085        0  ...     11  2017  Spring       0           0         0     0   \n",
              "235086        0  ...     11  2017  Spring       0           0         0     0   \n",
              "\n",
              "        Gender  sexual_orientation  Target  \n",
              "0            0                   0       0  \n",
              "1            0                   0       1  \n",
              "2            0                   0       0  \n",
              "3            0                   0       0  \n",
              "4            0                   0       0  \n",
              "...        ...                 ...     ...  \n",
              "235082       0                   0       0  \n",
              "235083       0                   0       0  \n",
              "235084       0                   0       0  \n",
              "235085       0                   0       0  \n",
              "235086       0                   0       0  \n",
              "\n",
              "[235087 rows x 60 columns]>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Checking the info of the dataset\n",
        "data1.info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcHy8Oz_3bbD"
      },
      "outputs": [],
      "source": [
        "#Step 1: NLP pre processing\n",
        "#Prepocessing the text (description column). i.e- removing the stop words and lemmatizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_jk2iiZs4Iqr",
        "outputId": "42f64937-8ca3-41d3-8dae-66d3338d939c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QrYPa3cy3gWC",
        "outputId": "ab8b4bf2-d703-4064-85c3-83149a6e75d1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer,PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "import string\n",
        "nltk.download('stopwords')\n",
        "stop=set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "      corpus=[]\n",
        "      #stem=PorterStemmer()\n",
        "      lem=WordNetLemmatizer()\n",
        "      for news in text:\n",
        "          words=[w for w in word_tokenize(news) if (w not in stop)]\n",
        "          \n",
        "          words = [lem.lemmatize(w) for w in words if len(w)>2]\n",
        "          words = [''.join(c for c in s if c not in string.punctuation) for s in words if s]\n",
        "          words = [word.lower() for word in words]\n",
        "          words = [word for word in words if word.isalpha()]\n",
        "          corpus.append(words) \n",
        "         \n",
        "      return corpus     \n",
        "      \n",
        "data1['processed_comment_text']= preprocess_text(data1['comment_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLah3ndv5Fa1"
      },
      "outputs": [],
      "source": [
        "#Printing the first 5 elements of the dataset\n",
        "data1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIMxzDn65MP9"
      },
      "outputs": [],
      "source": [
        "#Viewing the processed text.\n",
        "data1['processed_comment_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8BwL01b5T2r",
        "outputId": "b2af9577-853a-4587-ec98-5e679a87d97d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Maximum length of the sentence in processed text (in list) : 149\n"
          ]
        }
      ],
      "source": [
        "#Finding and printing the maximum length of the sentence in the processed text\n",
        "lgt = []\n",
        "for i in data1['processed_comment_text']:\n",
        "  lgt.append(len(i))\n",
        "print('Maximum length of the sentence in processed text (in list) :',max(lgt))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 543
        },
        "id": "74l_saXD5bac",
        "outputId": "ba003db5-653e-4143-a45f-8bdc0c42b318"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b1a15475-51bb-455b-a48c-af75dfd86951\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>target</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>severe_toxicity</th>\n",
              "      <th>obscene</th>\n",
              "      <th>identity_attack</th>\n",
              "      <th>insult</th>\n",
              "      <th>threat</th>\n",
              "      <th>asian</th>\n",
              "      <th>atheist</th>\n",
              "      <th>...</th>\n",
              "      <th>Season</th>\n",
              "      <th>Attack</th>\n",
              "      <th>Disability</th>\n",
              "      <th>Religion</th>\n",
              "      <th>Race</th>\n",
              "      <th>Gender</th>\n",
              "      <th>sexual_orientation</th>\n",
              "      <th>Target</th>\n",
              "      <th>processed_comment_text</th>\n",
              "      <th>comment_text_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>239579</td>\n",
              "      <td>0.4400</td>\n",
              "      <td>This is a great story. Man. I wonder if the pe...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>Summer</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[this, great, story, man, wonder, person, yell...</td>\n",
              "      <td>this great story man wonder person yelled shut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>239607</td>\n",
              "      <td>0.9125</td>\n",
              "      <td>Yet call out all Muslims for the acts of a few...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>Summer</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>[yet, call, muslims, act, get, pilloried, okay...</td>\n",
              "      <td>yet call muslims act get pilloried okay smear ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>239644</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>Because the people who drive cars more are the...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>Summer</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[because, people, drive, car, one, cause, wear...</td>\n",
              "      <td>because people drive car one cause wear tear r...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>239653</td>\n",
              "      <td>0.3000</td>\n",
              "      <td>Mormons have had a complicated relationship wi...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>Summer</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[mormons, complicated, relationship, federal, ...</td>\n",
              "      <td>mormons complicated relationship federal law</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>239744</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>I'm doing the same thing! :)</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>Summer</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[thing]</td>\n",
              "      <td>thing</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 62 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b1a15475-51bb-455b-a48c-af75dfd86951')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b1a15475-51bb-455b-a48c-af75dfd86951 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b1a15475-51bb-455b-a48c-af75dfd86951');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       id  target                                       comment_text  \\\n",
              "0  239579  0.4400  This is a great story. Man. I wonder if the pe...   \n",
              "1  239607  0.9125  Yet call out all Muslims for the acts of a few...   \n",
              "2  239644  0.0000  Because the people who drive cars more are the...   \n",
              "3  239653  0.3000  Mormons have had a complicated relationship wi...   \n",
              "4  239744  0.0000                       I'm doing the same thing! :)   \n",
              "\n",
              "   severe_toxicity  obscene  identity_attack  insult  threat  asian  atheist  \\\n",
              "0                0        0                0       0       0      0        0   \n",
              "1                0        0                1       1       0      0        0   \n",
              "2                0        0                0       0       0      0        0   \n",
              "3                0        0                0       0       0      0        0   \n",
              "4                0        0                0       0       0      0        0   \n",
              "\n",
              "   ...  Season  Attack  Disability  Religion  Race  Gender  \\\n",
              "0  ...  Summer       0           0         0     0       0   \n",
              "1  ...  Summer       1           0         2     0       0   \n",
              "2  ...  Summer       0           0         0     0       0   \n",
              "3  ...  Summer       0           0         0     0       0   \n",
              "4  ...  Summer       0           0         0     0       0   \n",
              "\n",
              "   sexual_orientation  Target  \\\n",
              "0                   0       0   \n",
              "1                   0       1   \n",
              "2                   0       0   \n",
              "3                   0       0   \n",
              "4                   0       0   \n",
              "\n",
              "                              processed_comment_text  \\\n",
              "0  [this, great, story, man, wonder, person, yell...   \n",
              "1  [yet, call, muslims, act, get, pilloried, okay...   \n",
              "2  [because, people, drive, car, one, cause, wear...   \n",
              "3  [mormons, complicated, relationship, federal, ...   \n",
              "4                                            [thing]   \n",
              "\n",
              "                              comment_text_processed  \n",
              "0  this great story man wonder person yelled shut...  \n",
              "1  yet call muslims act get pilloried okay smear ...  \n",
              "2  because people drive car one cause wear tear r...  \n",
              "3       mormons complicated relationship federal law  \n",
              "4                                              thing  \n",
              "\n",
              "[5 rows x 62 columns]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comment_processed = []\n",
        "for i in range(len(data1['processed_comment_text'])):\n",
        "   comment_processed.append(' '.join(wrd for wrd in data1.iloc[:,60][i]))\n",
        "data1['comment_text_processed'] = comment_processed\n",
        "data1.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpjwOwXT6izp"
      },
      "outputs": [],
      "source": [
        "#Number of characters present in each sentence\n",
        "#data1['comment_text'].str.len().hist();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d5m6QxV86wRI"
      },
      "outputs": [],
      "source": [
        "\n",
        "#data1['comment_text_processed'].str.len().hist();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tRujOZ9r68oy"
      },
      "outputs": [],
      "source": [
        "#Number of words appearing in each description\n",
        "#data1['comment_text'].str.split().map(lambda x: len(x)).hist();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6xt85sNq7JMN"
      },
      "outputs": [],
      "source": [
        "#Number of words appearing in each description\n",
        "#data1['comment_text_processed'].str.split().map(lambda x: len(x)).hist();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "twtqQhGW7Q8t"
      },
      "outputs": [],
      "source": [
        "'''#Average word length\n",
        "import numpy as np\n",
        "data1['comment_text'].str.split().apply(lambda x : [len(i) for i in x]). \\\n",
        "   map(lambda x: np.mean(x)).hist();'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V0XL6N597d3A"
      },
      "outputs": [],
      "source": [
        "'''data1['comment_text_processed'].str.split().apply(lambda x : [len(i) for i in x]). \\\n",
        "   map(lambda x: np.mean(x)).hist();'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "26Kuz42B7iNm"
      },
      "outputs": [],
      "source": [
        "'''#N-gram analysis\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_top_ngrams_barchart(text, n=2):\n",
        "    stop=set(stopwords.words('english'))\n",
        "\n",
        "    new= text.str.split()\n",
        "    new=new.values.tolist()\n",
        "    corpus=[word for i in new for word in i]\n",
        "\n",
        "    def get_top_ngram(corpus, n=None):\n",
        "        vec = CountVectorizer(ngram_range=(n, n)).fit(corpus)\n",
        "        bag_of_words = vec.transform(corpus)\n",
        "        sum_words = bag_of_words.sum(axis=0) \n",
        "        words_freq = [(word, sum_words[0, idx]) \n",
        "                      for word, idx in vec.vocabulary_.items()]\n",
        "        words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
        "        return words_freq[:10]\n",
        "\n",
        "    top_n_bigrams= get_top_ngram(text,n)[:10]\n",
        "    x,y=map(list,zip(*top_n_bigrams))\n",
        "    sns.barplot(x=y,y=x)'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-C2OEQVV7zBj"
      },
      "outputs": [],
      "source": [
        "#Bigram analysis\n",
        "#plot_top_ngrams_barchart(data1['comment_text_processed'],2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rSw6kveH73H0"
      },
      "outputs": [],
      "source": [
        "#Trigram analysis\n",
        "#plot_top_ngrams_barchart(data1['comment_text_processed'],3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYJLxZOx8BC8"
      },
      "outputs": [],
      "source": [
        "#For n=4\n",
        "#plot_top_ngrams_barchart(data1['comment_text_processed'],4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CRPJ6lVe8Ka8"
      },
      "outputs": [],
      "source": [
        "'''#Wordcloud\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "wordcloud = WordCloud(\n",
        "        background_color='white',\n",
        "        stopwords=set(STOPWORDS),\n",
        "        max_words=100,\n",
        "        max_font_size=30, \n",
        "        scale=3,\n",
        "        random_state=1)\n",
        "desc = data1['comment_text_processed']\n",
        "wordcloud=wordcloud.generate(str(desc))\n",
        "\n",
        "fig = plt.figure(1, figsize=(12, 12)) \n",
        "plt.axis('off')\n",
        " \n",
        "plt.imshow(wordcloud)\n",
        "plt.show()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-jB3_QyL-ak-"
      },
      "outputs": [],
      "source": [
        "test= '/content/drive/MyDrive/data/test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_KMjfxHe5vm"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9HmHdK8-hqU"
      },
      "outputs": [],
      "source": [
        "test=pd.read_csv(test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sJ72wvRn-rzs",
        "outputId": "1ed9bb41-6e53-4a00-f29f-fadb896f29b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5730f388-d269-436b-9af8-890cc8c08214\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7097320</td>\n",
              "      <td>[ Integrity means that you pay your debts.]\\n\\...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7097321</td>\n",
              "      <td>This is malfeasance by the Administrator and t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7097322</td>\n",
              "      <td>@Rmiller101 - Spoken like a true elitist. But ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7097323</td>\n",
              "      <td>Paul: Thank you for your kind words.  I do, in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7097324</td>\n",
              "      <td>Sorry you missed high school. Eisenhower sent ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5730f388-d269-436b-9af8-890cc8c08214')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5730f388-d269-436b-9af8-890cc8c08214 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5730f388-d269-436b-9af8-890cc8c08214');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id                                       comment_text\n",
              "0  7097320  [ Integrity means that you pay your debts.]\\n\\...\n",
              "1  7097321  This is malfeasance by the Administrator and t...\n",
              "2  7097322  @Rmiller101 - Spoken like a true elitist. But ...\n",
              "3  7097323  Paul: Thank you for your kind words.  I do, in...\n",
              "4  7097324  Sorry you missed high school. Eisenhower sent ..."
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HdPNgcubc8tv",
        "outputId": "424d8a13-9738-4177-88f2-d1beaaf3a44d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-97b2a4cf-081b-4ab7-b0ef-4d9d93de9b18\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>processed_comment_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7097320</td>\n",
              "      <td>[ Integrity means that you pay your debts.]\\n\\...</td>\n",
              "      <td>[integrity, mean, pay, debt, does, apply, pres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7097321</td>\n",
              "      <td>This is malfeasance by the Administrator and t...</td>\n",
              "      <td>[this, malfeasance, administrator, board, they...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7097322</td>\n",
              "      <td>@Rmiller101 - Spoken like a true elitist. But ...</td>\n",
              "      <td>[spoken, like, true, elitist, but, look, bud, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7097323</td>\n",
              "      <td>Paul: Thank you for your kind words.  I do, in...</td>\n",
              "      <td>[paul, thank, kind, word, indeed, strong, beli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7097324</td>\n",
              "      <td>Sorry you missed high school. Eisenhower sent ...</td>\n",
              "      <td>[sorry, missed, high, school, eisenhower, sent...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-97b2a4cf-081b-4ab7-b0ef-4d9d93de9b18')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-97b2a4cf-081b-4ab7-b0ef-4d9d93de9b18 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-97b2a4cf-081b-4ab7-b0ef-4d9d93de9b18');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id                                       comment_text  \\\n",
              "0  7097320  [ Integrity means that you pay your debts.]\\n\\...   \n",
              "1  7097321  This is malfeasance by the Administrator and t...   \n",
              "2  7097322  @Rmiller101 - Spoken like a true elitist. But ...   \n",
              "3  7097323  Paul: Thank you for your kind words.  I do, in...   \n",
              "4  7097324  Sorry you missed high school. Eisenhower sent ...   \n",
              "\n",
              "                              processed_comment_text  \n",
              "0  [integrity, mean, pay, debt, does, apply, pres...  \n",
              "1  [this, malfeasance, administrator, board, they...  \n",
              "2  [spoken, like, true, elitist, but, look, bud, ...  \n",
              "3  [paul, thank, kind, word, indeed, strong, beli...  \n",
              "4  [sorry, missed, high, school, eisenhower, sent...  "
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test['processed_comment_text']= preprocess_text(test['comment_text'])\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vljeQ663c8tv",
        "outputId": "99d4f261-2852-4e70-9ff3-49f21c37a71b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-acdc6c56-ada2-4cdf-a2b5-519adccb961b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>processed_comment_text</th>\n",
              "      <th>comment_text_processed</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7097320</td>\n",
              "      <td>[ Integrity means that you pay your debts.]\\n\\...</td>\n",
              "      <td>[integrity, mean, pay, debt, does, apply, pres...</td>\n",
              "      <td>integrity mean pay debt does apply president t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7097321</td>\n",
              "      <td>This is malfeasance by the Administrator and t...</td>\n",
              "      <td>[this, malfeasance, administrator, board, they...</td>\n",
              "      <td>this malfeasance administrator board they wast...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7097322</td>\n",
              "      <td>@Rmiller101 - Spoken like a true elitist. But ...</td>\n",
              "      <td>[spoken, like, true, elitist, but, look, bud, ...</td>\n",
              "      <td>spoken like true elitist but look bud the reaw...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7097323</td>\n",
              "      <td>Paul: Thank you for your kind words.  I do, in...</td>\n",
              "      <td>[paul, thank, kind, word, indeed, strong, beli...</td>\n",
              "      <td>paul thank kind word indeed strong belief nt h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7097324</td>\n",
              "      <td>Sorry you missed high school. Eisenhower sent ...</td>\n",
              "      <td>[sorry, missed, high, school, eisenhower, sent...</td>\n",
              "      <td>sorry missed high school eisenhower sent troop...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acdc6c56-ada2-4cdf-a2b5-519adccb961b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acdc6c56-ada2-4cdf-a2b5-519adccb961b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acdc6c56-ada2-4cdf-a2b5-519adccb961b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "        id                                       comment_text  \\\n",
              "0  7097320  [ Integrity means that you pay your debts.]\\n\\...   \n",
              "1  7097321  This is malfeasance by the Administrator and t...   \n",
              "2  7097322  @Rmiller101 - Spoken like a true elitist. But ...   \n",
              "3  7097323  Paul: Thank you for your kind words.  I do, in...   \n",
              "4  7097324  Sorry you missed high school. Eisenhower sent ...   \n",
              "\n",
              "                              processed_comment_text  \\\n",
              "0  [integrity, mean, pay, debt, does, apply, pres...   \n",
              "1  [this, malfeasance, administrator, board, they...   \n",
              "2  [spoken, like, true, elitist, but, look, bud, ...   \n",
              "3  [paul, thank, kind, word, indeed, strong, beli...   \n",
              "4  [sorry, missed, high, school, eisenhower, sent...   \n",
              "\n",
              "                              comment_text_processed  \n",
              "0  integrity mean pay debt does apply president t...  \n",
              "1  this malfeasance administrator board they wast...  \n",
              "2  spoken like true elitist but look bud the reaw...  \n",
              "3  paul thank kind word indeed strong belief nt h...  \n",
              "4  sorry missed high school eisenhower sent troop...  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "comment_processed = []\n",
        "for i in range(len(test['processed_comment_text'])):\n",
        "   comment_processed.append(' '.join(wrd for wrd in test.iloc[:,2][i]))\n",
        "test['comment_text_processed'] = comment_processed\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LukSoGbJ1Zgd",
        "outputId": "b5872117-6b49-4aa3-8c5c-e1d2c2aacbaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "10498/10498 [==============================] - 434s 41ms/step - loss: 0.3892 - accuracy: 0.8197 - val_loss: 0.2979 - val_accuracy: 0.8691\n",
            "Epoch 2/3\n",
            "10498/10498 [==============================] - 415s 40ms/step - loss: 0.2504 - accuracy: 0.8933 - val_loss: 0.2683 - val_accuracy: 0.8852\n",
            "Epoch 3/3\n",
            "10498/10498 [==============================] - 370s 35ms/step - loss: 0.1951 - accuracy: 0.9194 - val_loss: 0.2573 - val_accuracy: 0.8900\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "import pickle\n",
        "\n",
        "def create_model():\n",
        "    # Separate the text and label data\n",
        "    text_data = data1['comment_text_processed']\n",
        "    label_data = data1['Target']\n",
        "    \n",
        "    # Define the text tokenizer\n",
        "    tokenizer = Tokenizer(num_words=10000)\n",
        "    tokenizer.fit_on_texts(text_data)\n",
        "    \n",
        "    # Convert the text data to integer sequences and pad them to the same length\n",
        "    text_data_seq = tokenizer.texts_to_sequences(text_data)\n",
        "    text_data_padded = pad_sequences(text_data_seq, padding='post', maxlen=500)\n",
        "    \n",
        "    # Apply SMOTE to the text and label data\n",
        "    smote = SMOTE(random_state=42)\n",
        "    text_data_smote, label_data_smote = smote.fit_resample(text_data_padded, label_data)\n",
        "    \n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_cv8, y_train, y_cv8 = train_test_split(text_data_smote, label_data_smote, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define and train the BiLSTM model\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=10000, output_dim=128, input_length=500))\n",
        "    model.add(Bidirectional(LSTM(64)))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model.fit(X_train, y_train, validation_data=(X_cv8, y_cv8), epochs=3, batch_size=32)\n",
        "    \n",
        "    # Pickle the model\n",
        "    with open('model.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "        \n",
        "    return model\n",
        "\n",
        "# Call the function to create and pickle the model\n",
        "model = create_model()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cx2eocNS1Zgd"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "accuracy = accuracy_score(y_test4, y_pred)\n",
        "precision = precision_score(y_test4, y_pred)\n",
        "recall = recall_score(y_test4, y_pred)\n",
        "f1 = f1_score(y_test4, y_pred)\n",
        "\n",
        "print('Accuracy:', accuracy)\n",
        "print('Precision:', precision)\n",
        "print('Recall:', recall)\n",
        "print('F1 score:', f1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_w8mUQyu5BcT",
        "outputId": "e20eff05-5bff-4d1f-b731-61d9d7564f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2747/8398 [========>.....................] - ETA: 4:05:51 - loss: 0.5247 - accuracy: 0.7416"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "\n",
        "# Split the DataFrame into a text array and a label array\n",
        "text_data4 = data1['comment_text_processed'].to_numpy()\n",
        "label_data4 = data1['Target'].to_numpy()\n",
        "\n",
        "# Define the text vectorizer layer\n",
        "vectorizer5 = TextVectorization(\n",
        "    max_tokens=10000, # maximum number of unique words to keep in the vocabulary\n",
        "    output_mode='int', # output integer indices for each word in the vocabulary\n",
        "    output_sequence_length=500 # maximum sequence length to pad/truncate all input sequences to\n",
        ")\n",
        "\n",
        "# Fit the text vectorizer layer to your text data\n",
        "vectorizer5.adapt(text_data4)\n",
        "\n",
        "# Convert the text data to preprocessed integer sequences\n",
        "text_data4 = vectorizer5(text_data4)\n",
        "\n",
        "# Apply SMOTE to the text and label data\n",
        "smote = SMOTE(random_state=42)\n",
        "text_data_smote, label_data_smote = smote.fit_resample(text_data4, label_data4)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train5, X_test5, y_train5, y_test5 = train_test_split(text_data_smote, label_data_smote, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define and train the LSTM model\n",
        "model1 = Sequential([\n",
        "    Embedding(\n",
        "        input_dim=len(vectorizer5.get_vocabulary()), # size of the vocabulary\n",
        "        output_dim=128, # size of the embedding space\n",
        "        mask_zero=True # use masking to handle variable-length input sequences\n",
        "    ),\n",
        "    LSTM(128, return_sequences=True),\n",
        "    LSTM(64),\n",
        "    Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5), # add a dropout layer to reduce overfitting\n",
        "    Dense(1, activation='sigmoid') # binary classification output layer\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model1.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model1.fit(\n",
        "    X_train5, y_train5,\n",
        "    batch_size=32,\n",
        "    epochs=1,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "# Evaluate the model on the train set\n",
        "train_loss1, train_acc1 = model1.evaluate(X_train5, y_train5)\n",
        "print('Train accuracy:', train_acc1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss1, test_acc1 = model1.evaluate(X_test5, y_test5)\n",
        "print('Test accuracy:', test_acc1)\n",
        "\n",
        "# Save the trained model as a pickle file\n",
        "with open('model1.pickle', 'wb') as handle:\n",
        "    pickle.dump(model1, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Elkm89y3B2u7",
        "outputId": "005847e6-004e-4300-fbb7-ef33a3494b85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "10498/10498 [==============================] - 885s 83ms/step - loss: 0.3925 - accuracy: 0.8171 - val_loss: 0.3027 - val_accuracy: 0.8682\n",
            "Epoch 2/3\n",
            "10498/10498 [==============================] - 776s 74ms/step - loss: 0.2488 - accuracy: 0.8940 - val_loss: 0.2461 - val_accuracy: 0.8941\n",
            "Epoch 3/3\n",
            "10498/10498 [==============================] - 756s 72ms/step - loss: 0.1952 - accuracy: 0.9187 - val_loss: 0.2482 - val_accuracy: 0.8959\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "    # Separate the text and label data\n",
        "    text_data = data1['comment_text_processed']\n",
        "    label_data = data1['Target']\n",
        "    \n",
        "    # Define the text vectorizer layer\n",
        "    vectorizer = TextVectorization(\n",
        "    max_tokens=10000,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=500\n",
        "    )\n",
        "\n",
        "    # Fit the text vectorizer layer to your text data\n",
        "    vectorizer.adapt(text_data1)\n",
        "\n",
        "    # Convert the text data to preprocessed integer sequences\n",
        "    text_data1 = vectorizer(text_data1)\n",
        "    \n",
        "    # Apply SMOTE to the text and label data\n",
        "    smote = SMOTE(random_state=42)\n",
        "    text_data_smote, label_data_smote = smote.fit_resample(text_data1, label_data)\n",
        "    \n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_cv8, y_train, y_cv8 = train_test_split(text_data_smote, label_data_smote, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Define and train the BiLSTM model\n",
        "    model3 = Sequential()\n",
        "    model3.add(Embedding(input_dim=10000, output_dim=128, input_length=500))\n",
        "    model3.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    model3.add(tf.keras.layers.Dropout(0.2))\n",
        "    model3.add(Bidirectional(LSTM(64)))\n",
        "    model3.add(tf.keras.layers.Dropout(0.2))\n",
        "    model3.add(Dense(64, activation='relu'))\n",
        "    model3.add(Dense(32, activation='relu'))\n",
        "    model3.add(Dense(1, activation='sigmoid'))\n",
        "    model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model3.fit(X_train, y_train, validation_data=(X_cv8, y_cv8), epochs=3, batch_size=32)\n",
        "    \n",
        "    # Pickle the model\n",
        "    with open('model3.pkl', 'wb') as f:\n",
        "        pickle.dump(model3, f)\n",
        "        \n",
        "    return model3\n",
        "\n",
        "# Call the function to create and pickle the model\n",
        "model3 = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOPzIXxSQnNX",
        "outputId": "7bb25eef-75e2-4d4d-dc7b-267fcdb19cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "9448/9448 [==============================] - 825s 86ms/step - loss: 0.3997 - accuracy: 0.8107 - val_loss: 0.2883 - val_accuracy: 0.8733\n",
            "Epoch 2/3\n",
            "9448/9448 [==============================] - 662s 70ms/step - loss: 0.2536 - accuracy: 0.8921 - val_loss: 0.2515 - val_accuracy: 0.8899\n",
            "Epoch 3/3\n",
            "9448/9448 [==============================] - 650s 69ms/step - loss: 0.2069 - accuracy: 0.9138 - val_loss: 0.2441 - val_accuracy: 0.8947\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "    # Separate the text and label data\n",
        "    text_data = data1['comment_text_processed']\n",
        "    label_data = data1['Target']\n",
        "    \n",
        "    # Define the text vectorizer layer\n",
        "    vectorizer = TextVectorization(\n",
        "    max_tokens=10000,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=500\n",
        "    )\n",
        "\n",
        "    # Fit the text vectorizer layer to your text data\n",
        "    vectorizer.adapt(text_data)\n",
        "\n",
        "    # Convert the text data to preprocessed integer sequences\n",
        "    text_data1 = vectorizer(text_data)\n",
        "    \n",
        "    # Apply SMOTE to the text and label data\n",
        "    smote = SMOTE(random_state=42)\n",
        "    text_data_smote, label_data_smote = smote.fit_resample(text_data1, label_data)\n",
        "    \n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_cv8, y_train, y_cv8 = train_test_split(text_data_smote, label_data_smote, test_size=0.2, random_state=42)\n",
        "    early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "    # Define and train the BiLSTM model\n",
        "    model3 = Sequential()\n",
        "    model3.add(Embedding(input_dim=10000, output_dim=128, input_length=500))\n",
        "    model3.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    #model3.add(tf.keras.layers.Dropout(0.2))\n",
        "    model3.add(Bidirectional(LSTM(64)))\n",
        "    model3.add(tf.keras.layers.Dropout(0.2))\n",
        "    model3.add(Dense(64, activation='relu'))\n",
        "    model3.add(Dense(32, activation='relu'))\n",
        "    model3.add(Dense(1, activation='sigmoid'))\n",
        "    model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model3.fit(X_train, y_train, validation_split=0.1, epochs=3, batch_size=32,callbacks=[early_stopping],verbose=1)\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss1, test_acc1 = model3.evaluate(X_cv8, y_cv8)\n",
        "    print('Test accuracy:', test_acc1)\n",
        "\n",
        "    \n",
        "    # Pickle the model\n",
        "    with open('model3.pkl', 'wb') as f:\n",
        "        pickle.dump(model3, f)\n",
        "        \n",
        "    return model3\n",
        "\n",
        "# Call the function to create and pickle the model\n",
        "model3 = create_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVvQaUn5a2ej",
        "outputId": "9a09be73-6ee8-460f-931a-177b21953e91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "8398/8398 [==============================] - 742s 87ms/step - loss: 0.3832 - accuracy: 0.8258 - val_loss: 0.2793 - val_accuracy: 0.8770\n",
            "Epoch 2/3\n",
            "8398/8398 [==============================] - 638s 76ms/step - loss: 0.2483 - accuracy: 0.8951 - val_loss: 0.2469 - val_accuracy: 0.8941\n",
            "Epoch 3/3\n",
            "8398/8398 [==============================] - 632s 75ms/step - loss: 0.1928 - accuracy: 0.9202 - val_loss: 0.2427 - val_accuracy: 0.8960\n",
            "2625/2625 [==============================] - 73s 28ms/step - loss: 0.2429 - accuracy: 0.8946\n",
            "Test accuracy: 0.8945914506912231\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dense\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_model():\n",
        "    # Separate the text and label data\n",
        "    text_data = data1['comment_text_processed']\n",
        "    label_data = data1['Target']\n",
        "    \n",
        "    # Define the text vectorizer layer\n",
        "    vectorizer = TextVectorization(\n",
        "    max_tokens=10000,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=500\n",
        "    )\n",
        "\n",
        "    # Fit the text vectorizer layer to your text data\n",
        "    vectorizer.adapt(text_data)\n",
        "\n",
        "    # Convert the text data to preprocessed integer sequences\n",
        "    text_data1 = vectorizer(text_data)\n",
        "    \n",
        "    # Apply SMOTE to the text and label data\n",
        "    smote = SMOTE(random_state=42)\n",
        "    text_data_smote, label_data_smote = smote.fit_resample(text_data1, label_data)\n",
        "    \n",
        "    # Split the data into training and testing sets\n",
        "    X_train, X_cv8, y_train, y_cv8 = train_test_split(text_data_smote, label_data_smote, test_size=0.2, random_state=42)\n",
        "    early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "    # Define and train the BiLSTM model\n",
        "    model4 = Sequential()\n",
        "    model4.add(Embedding(input_dim=10000, output_dim=128, input_length=500))\n",
        "    model4.add(Bidirectional(LSTM(128, return_sequences=True)))\n",
        "    #model3.add(tf.keras.layers.Dropout(0.2))\n",
        "    model4.add(Bidirectional(LSTM(64)))\n",
        "    model4.add(tf.keras.layers.Dropout(0.4))\n",
        "    model4.add(Dense(64, activation='relu'))\n",
        "    model4.add(Dense(32, activation='relu'))\n",
        "    model4.add(Dense(1, activation='sigmoid'))\n",
        "    model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    model4.fit(X_train, y_train, validation_split=0.2, epochs=3, batch_size=32,callbacks=[early_stopping],verbose=1)\n",
        "    # Evaluate the model on the test set\n",
        "    test_loss1, test_acc1 = model4.evaluate(X_cv8, y_cv8)\n",
        "    print('Test accuracy:', test_acc1)\n",
        "\n",
        "    \n",
        "    # Pickle the model\n",
        "    with open('model4.pkl', 'wb') as f:\n",
        "        pickle.dump(model4, f)\n",
        "        \n",
        "    return model4\n",
        "\n",
        "# Call the function to create and pickle the model\n",
        "model4 = create_model()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}